{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe opencv-python tensorflow numpy pandas scikit-learn"
      ],
      "metadata": {
        "id": "Z5pUOyPq-KUA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import pickle"
      ],
      "metadata": {
        "id": "sKVDsVdE-X6c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
        "options = vision.HandLandmarkerOptions(\n",
        "    base_options=base_options,\n",
        "    num_hands=1\n",
        ")\n",
        "detector = vision.HandLandmarker.create_from_options(options)\n",
        "print(\"Detector ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaB69Pwn-aAW",
        "outputId": "45e2c7b5-f71f-4723-fb85-32eb35b8853f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detector ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_landmarks(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=img_rgb)\n",
        "\n",
        "    result = detector.detect(mp_image)\n",
        "\n",
        "    if not result.hand_landmarks:\n",
        "        return None\n",
        "\n",
        "    hand = result.hand_landmarks[0]\n",
        "    vector = []\n",
        "    for lm in hand:\n",
        "        vector.extend([lm.x, lm.y, lm.z])\n",
        "\n",
        "    return vector"
      ],
      "metadata": {
        "id": "CArAZaQM-b-i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/isl_dataset/Indian\"\n",
        "MAX_IMAGES_PER_CLASS = 100\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "folders = sorted(os.listdir(DATASET_PATH))\n",
        "print(f\"Found {len(folders)} classes: {folders}\\n\")\n",
        "\n",
        "for label in folders:\n",
        "    label_path = os.path.join(DATASET_PATH, label)\n",
        "\n",
        "    if not os.path.isdir(label_path):\n",
        "        continue\n",
        "\n",
        "    image_files = [f for f in os.listdir(label_path)\n",
        "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    image_files = image_files[:MAX_IMAGES_PER_CLASS]\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    for img_file in image_files:\n",
        "        img_path = os.path.join(label_path, img_file)\n",
        "        features = extract_landmarks(img_path)\n",
        "\n",
        "        if features is not None:\n",
        "            X.append(features)\n",
        "            y.append(label)\n",
        "            success_count += 1\n",
        "\n",
        "    print(f\"{label}: {success_count}/{len(image_files)} images processed\")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"\\nFinal dataset: X shape = {X.shape}, y shape = {y.shape}\")\n",
        "print(f\"Unique classes: {len(np.unique(y))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5ATv7hPs-eFZ",
        "outputId": "b14ca9e9-f010-48bd-ff59-444ea9bf3607"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 35 classes: ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
            "\n",
            "1: 100/100 images processed\n",
            "2: 100/100 images processed\n",
            "3: 100/100 images processed\n",
            "4: 100/100 images processed\n",
            "5: 100/100 images processed\n",
            "6: 100/100 images processed\n",
            "7: 100/100 images processed\n",
            "8: 100/100 images processed\n",
            "9: 100/100 images processed\n",
            "A: 100/100 images processed\n",
            "B: 100/100 images processed\n",
            "C: 93/100 images processed\n",
            "D: 100/100 images processed\n",
            "E: 100/100 images processed\n",
            "F: 100/100 images processed\n",
            "G: 100/100 images processed\n",
            "H: 100/100 images processed\n",
            "I: 100/100 images processed\n",
            "J: 100/100 images processed\n",
            "K: 100/100 images processed\n",
            "L: 100/100 images processed\n",
            "M: 100/100 images processed\n",
            "N: 83/100 images processed\n",
            "O: 95/100 images processed\n",
            "P: 85/100 images processed\n",
            "Q: 66/100 images processed\n",
            "R: 100/100 images processed\n",
            "S: 51/100 images processed\n",
            "T: 100/100 images processed\n",
            "U: 100/100 images processed\n",
            "V: 100/100 images processed\n",
            "W: 100/100 images processed\n",
            "X: 100/100 images processed\n",
            "Y: 100/100 images processed\n",
            "Z: 100/100 images processed\n",
            "\n",
            "Final dataset: X shape = (3373, 63), y shape = (3373,)\n",
            "Unique classes: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X) == 0:\n",
        "    print(\"ERROR: No data loaded\")\n",
        "else:\n",
        "    print(f\"SUCCESS: {len(X)} samples loaded\")\n",
        "    print(f\"Feature size: {X.shape[1]}\")\n",
        "    print(f\"Classes: {sorted(np.unique(y))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY8TMdub-kAu",
        "outputId": "90f3b1fc-0992-485d-bb04-abd840348695"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: 3373 samples loaded\n",
            "Feature size: 63\n",
            "Classes: [np.str_('1'), np.str_('2'), np.str_('3'), np.str_('4'), np.str_('5'), np.str_('6'), np.str_('7'), np.str_('8'), np.str_('9'), np.str_('A'), np.str_('B'), np.str_('C'), np.str_('D'), np.str_('E'), np.str_('F'), np.str_('G'), np.str_('H'), np.str_('I'), np.str_('J'), np.str_('K'), np.str_('L'), np.str_('M'), np.str_('N'), np.str_('O'), np.str_('P'), np.str_('Q'), np.str_('R'), np.str_('S'), np.str_('T'), np.str_('U'), np.str_('V'), np.str_('W'), np.str_('X'), np.str_('Y'), np.str_('Z')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"Train: {X_train.shape}\")\n",
        "print(f\"Test: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpmeeES9CFzY",
        "outputId": "34657240-d117-4d06-f538-dc319a33e870"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (2698, 63)\n",
            "Test: (675, 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(63,)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "7UZcLe1BCIiM",
        "outputId": "f255c297-963e-4c75-c941-05f888e1e933"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m16,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m2,275\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,275</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61,347\u001b[0m (239.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,347</span> (239.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,579\u001b[0m (236.64 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,579</span> (236.64 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=60,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FVCyd5YVCLfY",
        "outputId": "99d2f78a-ab5c-479c-b12f-2b31a3bb1dce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1180 - val_accuracy: 0.9985 - val_loss: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 2/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1025 - val_accuracy: 0.9985 - val_loss: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 3/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9702 - loss: 0.0913 - val_accuracy: 0.9985 - val_loss: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 4/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.1134 - val_accuracy: 0.9985 - val_loss: 0.0028 - learning_rate: 1.0000e-05\n",
            "Epoch 5/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.1051 - val_accuracy: 0.9985 - val_loss: 0.0027 - learning_rate: 1.0000e-05\n",
            "Epoch 6/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9610 - loss: 0.1200 - val_accuracy: 0.9985 - val_loss: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 7/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9695 - loss: 0.1030 - val_accuracy: 0.9985 - val_loss: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 8/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1020 - val_accuracy: 0.9985 - val_loss: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 9/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.1025 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 10/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.0979 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 11/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1110 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 12/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.1066 - val_accuracy: 0.9985 - val_loss: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 13/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.1014 - val_accuracy: 0.9985 - val_loss: 0.0026 - learning_rate: 1.0000e-05\n",
            "Epoch 14/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9713 - loss: 0.1004 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 15/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9701 - loss: 0.1023 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 16/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9655 - loss: 0.1215 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 17/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9686 - loss: 0.0983 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 18/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.1010 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 19/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0982 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 20/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.1019 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 21/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0968 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 22/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.0905 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 23/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0996 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 24/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0904 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 25/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0888 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 26/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.1032 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 27/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.0858 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 28/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9693 - loss: 0.1049 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 29/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1075 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 30/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9575 - loss: 0.1191 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 31/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1112 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 32/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.0966 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 33/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.1158 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 34/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0869 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 35/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1267 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 36/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1065 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 37/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.1224 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 38/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9616 - loss: 0.1164 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 39/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9696 - loss: 0.0940 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 40/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.1002 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n",
            "Epoch 41/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.1059 - val_accuracy: 0.9985 - val_loss: 0.0025 - learning_rate: 1.0000e-05\n",
            "Epoch 42/60\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.0998 - val_accuracy: 0.9985 - val_loss: 0.0024 - learning_rate: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "print(f\"Train Accuracy: {train_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uViWuu6ZCOUp",
        "outputId": "d6dbdf14-0d5d-4975-d21a-66129863c4a8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 99.85%\n",
            "Test Loss: 0.0024\n",
            "Train Accuracy: 99.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"isl_hand_model.h5\")\n",
        "print(\"Model saved\")\n",
        "\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(encoder, f)\n",
        "print(\"Encoder saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kctGtNH2CdNV",
        "outputId": "7a0c65da-c570-4720-b78d-1d0eddb88c52"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n",
            "Encoder saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_idx = np.random.randint(0, len(X_test))\n",
        "sample = X_test[sample_idx].reshape(1, -1)\n",
        "actual = encoder.inverse_transform([y_test[sample_idx]])[0]\n",
        "\n",
        "pred = model.predict(sample, verbose=0)\n",
        "predicted = encoder.inverse_transform([np.argmax(pred)])[0]\n",
        "\n",
        "print(f\"Actual: {actual}\")\n",
        "print(f\"Predicted: {predicted}\")\n",
        "print(f\"Confidence: {np.max(pred) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QGFnNCgCqw7",
        "outputId": "2f272ffc-ac2a-4504-cf59-e7315cf6e1b3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: E\n",
            "Predicted: E\n",
            "Confidence: 99.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-ynebMJDnKj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
